{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: pyspark==2.4.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (2.4.5)\r\nRequirement already satisfied: py4j==0.10.7 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pyspark==2.4.5) (0.10.7)\r\n"
                }
            ],
            "source": "!pip install pyspark==2.4.5"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "try:\n    from pyspark import SparkContext, SparkConf\n    from pyspark.sql import SparkSession\nexcept ImportError as e:\n    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "8.8 10.562196741208714 2.0207040735991666 3.663124005193276\n3.5\n"
                }
            ],
            "source": "rdd=sc.parallelize([34,1,23,4,3,3,12,4,3,1])\nsum = rdd.sum()\nn = rdd.count()\nn = float(n)\nmean = sum/n\n\nfrom math import sqrt\n\nsd = sqrt (rdd.map(lambda x : pow(x-mean,2)).sum()/n)\n\nskewness = rdd.map(lambda x : pow(x-mean,3)/pow(sd,3)).sum()*n/((n-1)*(n-2))\n\nkurtosis  = rdd.map(lambda x : pow(x-mean,4)/pow(sd,4)).sum()/n\n\nprint(mean,sd,skewness,kurtosis)\n\nimport statistics\nprint(statistics.median([1,2,4,5,34,1,32,4,34,2,1,3]))"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "3.65 0.3022347607034227 [[1, 7, 14, 29], [2, 6, 13, 28], [3, 5, 16, 27], [4, 4, 19, 26], [5, 5, 11, 25], [6, 6, 17, 24], [7, 7, 10, 23], [8, 8, 15, 22], [9, 9, 18, 21], [10, 10, 12, 20]] [[ 1.          0.70927291 -0.05454545 -1.        ]\n [ 0.70927291  1.         -0.20403741 -0.70927291]\n [-0.05454545 -0.20403741  1.          0.05454545]\n [-1.         -0.70927291  0.05454545  1.        ]]\n"
                }
            ],
            "source": "import random \nfrom pyspark.mllib.stat import Statistics\n\nrddX = sc.parallelize([1,2,3,4,5,6,7,8,9,10])\nrddY = sc.parallelize([7,6,5,4,5,6,7,8,9,10])\nrddZ = sc.parallelize(random.sample(range(10,20),10))\nrddK = sc.parallelize(list(reversed(range(20,30))))\n\ndata=rddX.zip(rddY).zip(rddZ).zip(rddK).map(lambda var : [var[0][0][0],var[0][0][1],var[0][1],var[1]])\n\nmeanX = rddX.sum()/rddX.count()\nmeanY = rddY.sum()/rddY.count()\n\nrddXY = rddX.zip(rddY)\nn=rddXY.count()\ncovXY = rddXY.map( lambda var : (var[0]-meanX)*(var[1]-meanY)).sum()/n\nsdX = sqrt (rddX.map(lambda x : pow(x-mean,2)).sum()/n)\nsdY = sqrt (rddY.map(lambda x : pow(x-mean,2)).sum()/n)\ncorrXY = covXY / (sdX*sdY)\n\nprint(covXY, corrXY, data.take(10),Statistics.corr(data))"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "3.65 0.3022347607034227\n"
                }
            ],
            "source": "rddX = sc.parallelize([1,2,3,4,5,6,7,8,9,10])\nrddY = sc.parallelize([7,6,5,4,5,6,7,8,9,10])\n\n\nmeanX = rddX.sum()/rddX.count()\nmeanY = rddY.sum()/rddY.count()\n\nrddXY = rddX.zip(rddY)\nn=rddXY.count()\ncovXY = rddXY.map( lambda var : (var[0]-meanX)*(var[1]-meanY)).sum()/n\nsdX = sqrt (rddX.map(lambda x : pow(x-mean,2)).sum()/n)\nsdY = sqrt (rddY.map(lambda x : pow(x-mean,2)).sum()/n)\ncorrXY = covXY / (sdX*sdY)\n\nprint(covXY, corrXY)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}